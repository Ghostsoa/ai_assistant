package server

import (
	"bufio"
	"context"
	"fmt"
	"io"
	"log"
	"net"
	"os"
	"strings"

	"ai_assistant/internal/backup"
	appconfig "ai_assistant/internal/config"
	"ai_assistant/internal/process"
	"ai_assistant/internal/tools"

	"github.com/sashabaranov/go-openai"
)

const SocketPath = "/tmp/jarvis.sock"

var (
	client         *openai.Client
	executor       *tools.Executor
	processManager *process.Manager
	backupManager  *backup.Manager
)

// Start å¯åŠ¨ JARVIS å®ˆæŠ¤è¿›ç¨‹
func Start() error {
	// åˆ é™¤æ—§çš„ socket æ–‡ä»¶
	os.Remove(SocketPath)

	// åˆ›å»º Unix socket ç›‘å¬
	listener, err := net.Listen("unix", SocketPath)
	if err != nil {
		return fmt.Errorf("åˆ›å»º socket å¤±è´¥: %v", err)
	}
	defer os.Remove(SocketPath)

	fmt.Println("ðŸ¤– JARVIS Server å·²å¯åŠ¨")
	fmt.Printf("Socket: %s\n", SocketPath)

	// åˆå§‹åŒ– AI å®¢æˆ·ç«¯ï¼ˆåªåˆå§‹åŒ–ä¸€æ¬¡ï¼‰
	client = openai.NewClient(appconfig.GlobalConfig.APIKey)
	if appconfig.GlobalConfig.BaseURL != "" {
		config := openai.DefaultConfig(appconfig.GlobalConfig.APIKey)
		config.BaseURL = appconfig.GlobalConfig.BaseURL
		client = openai.NewClientWithConfig(config)
	}

	// åˆå§‹åŒ–å·¥å…·æ‰§è¡Œå™¨
	processManager = process.NewManager()
	backupManager = backup.NewManager()
	executor = tools.NewExecutor(processManager, backupManager)

	// ç›‘å¬è¿žæŽ¥
	for {
		conn, err := listener.Accept()
		if err != nil {
			log.Printf("æŽ¥å—è¿žæŽ¥å¤±è´¥: %v", err)
			continue
		}

		go handleClient(conn)
	}
}

// handleClient å¤„ç†å®¢æˆ·ç«¯è¯·æ±‚
func handleClient(conn net.Conn) {
	defer conn.Close()

	// è¯»å–è¯·æ±‚
	reader := bufio.NewReader(conn)
	query, err := reader.ReadString('\n')
	if err != nil {
		return
	}
	query = strings.TrimSpace(query)

	if query == "" {
		return
	}

	// å¤„ç† AI å¯¹è¯ï¼Œæµå¼è¾“å‡ºåˆ° conn
	streamChat(conn, query)
}

// streamChat æµå¼å¯¹è¯
func streamChat(writer io.Writer, query string) {
	ctx := context.Background()

	// æž„å»ºæ¶ˆæ¯
	messages := []openai.ChatCompletionMessage{
		{
			Role:    "user",
			Content: query,
		},
	}

	// åˆ›å»ºè¯·æ±‚
	req := openai.ChatCompletionRequest{
		Model:    appconfig.GlobalConfig.Model,
		Messages: messages,
		Tools:    tools.GetTools(),
		Stream:   true,
	}

	// åˆ›å»ºæµ
	stream, err := client.CreateChatCompletionStream(ctx, req)
	if err != nil {
		fmt.Fprintf(writer, "ERROR: %v\n", err)
		return
	}
	defer stream.Close()

	var fullResponse strings.Builder
	var toolCalls []openai.ToolCall
	var currentToolCall *openai.ToolCall

	// æµå¼æŽ¥æ”¶
	for {
		response, err := stream.Recv()
		if err == io.EOF {
			break
		}
		if err != nil {
			fmt.Fprintf(writer, "\nERROR: %v\n", err)
			return
		}

		if len(response.Choices) == 0 {
			continue
		}

		delta := response.Choices[0].Delta

		// å¤„ç†å†…å®¹
		if delta.Content != "" {
			fullResponse.WriteString(delta.Content)
			fmt.Fprint(writer, delta.Content)
		}

		// å¤„ç†å·¥å…·è°ƒç”¨
		if len(delta.ToolCalls) > 0 {
			for _, tc := range delta.ToolCalls {
				if tc.Index != nil {
					if int(*tc.Index) >= len(toolCalls) {
						toolCalls = append(toolCalls, openai.ToolCall{
							ID:   tc.ID,
							Type: tc.Type,
							Function: openai.FunctionCall{
								Name:      tc.Function.Name,
								Arguments: tc.Function.Arguments,
							},
						})
						currentToolCall = &toolCalls[*tc.Index]
					} else {
						currentToolCall = &toolCalls[*tc.Index]
					}
				}

				if currentToolCall != nil {
					if tc.ID != "" {
						currentToolCall.ID = tc.ID
					}
					if tc.Function.Name != "" {
						currentToolCall.Function.Name = tc.Function.Name
					}
					if tc.Function.Arguments != "" {
						currentToolCall.Function.Arguments += tc.Function.Arguments
					}
				}
			}
		}
	}

	fmt.Fprintln(writer)

	// æ‰§è¡Œå·¥å…·è°ƒç”¨
	if len(toolCalls) > 0 {
		for _, toolCall := range toolCalls {
			fmt.Fprintf(writer, "\n[å·¥å…·è°ƒç”¨: %s]\n", toolCall.Function.Name)
			result := executor.Execute(toolCall)
			fmt.Fprintln(writer, result)
		}
	}
}
